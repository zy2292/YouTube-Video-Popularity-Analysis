{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.util import ngrams\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import re\n",
    "import numpy as np\n",
    "import scipy\n",
    "\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from scipy.spatial.distance import cosine\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from scipy.sparse import coo_matrix\n",
    "\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from collections import Counter, OrderedDict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('C:/Users/chenq/Desktop/5291ADA/youtube-new/USvideos.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['trending_date', 'title', 'channel_title', 'category_id',\n",
       "       'publish_time', 'tags', 'views', 'likes', 'dislikes', 'comment_count',\n",
       "       'thumbnail_link', 'comments_disabled', 'ratings_disabled',\n",
       "       'video_error_or_removed', 'description'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trending_date</th>\n",
       "      <th>title</th>\n",
       "      <th>channel_title</th>\n",
       "      <th>category_id</th>\n",
       "      <th>publish_time</th>\n",
       "      <th>tags</th>\n",
       "      <th>views</th>\n",
       "      <th>likes</th>\n",
       "      <th>dislikes</th>\n",
       "      <th>comment_count</th>\n",
       "      <th>thumbnail_link</th>\n",
       "      <th>comments_disabled</th>\n",
       "      <th>ratings_disabled</th>\n",
       "      <th>video_error_or_removed</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>video_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2kyS6SvSYSE</th>\n",
       "      <td>17.14.11</td>\n",
       "      <td>WE WANT TO TALK ABOUT OUR MARRIAGE</td>\n",
       "      <td>CaseyNeistat</td>\n",
       "      <td>22</td>\n",
       "      <td>2017-11-13T17:13:01.000Z</td>\n",
       "      <td>SHANtell martin</td>\n",
       "      <td>748374</td>\n",
       "      <td>57527</td>\n",
       "      <td>2966</td>\n",
       "      <td>15954</td>\n",
       "      <td>https://i.ytimg.com/vi/2kyS6SvSYSE/default.jpg</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>SHANTELL'S CHANNEL - https://www.youtube.com/s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1ZAPwfrtAFY</th>\n",
       "      <td>17.14.11</td>\n",
       "      <td>The Trump Presidency: Last Week Tonight with J...</td>\n",
       "      <td>LastWeekTonight</td>\n",
       "      <td>24</td>\n",
       "      <td>2017-11-13T07:30:00.000Z</td>\n",
       "      <td>last week tonight trump presidency|\"last week ...</td>\n",
       "      <td>2418783</td>\n",
       "      <td>97185</td>\n",
       "      <td>6146</td>\n",
       "      <td>12703</td>\n",
       "      <td>https://i.ytimg.com/vi/1ZAPwfrtAFY/default.jpg</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>One year after the presidential election, John...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5qpjK5DgCt4</th>\n",
       "      <td>17.14.11</td>\n",
       "      <td>Racist Superman | Rudy Mancuso, King Bach &amp; Le...</td>\n",
       "      <td>Rudy Mancuso</td>\n",
       "      <td>23</td>\n",
       "      <td>2017-11-12T19:05:24.000Z</td>\n",
       "      <td>racist superman|\"rudy\"|\"mancuso\"|\"king\"|\"bach\"...</td>\n",
       "      <td>3191434</td>\n",
       "      <td>146033</td>\n",
       "      <td>5339</td>\n",
       "      <td>8181</td>\n",
       "      <td>https://i.ytimg.com/vi/5qpjK5DgCt4/default.jpg</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>WATCH MY PREVIOUS VIDEO ▶ \\n\\nSUBSCRIBE ► http...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>puqaWrEC7tY</th>\n",
       "      <td>17.14.11</td>\n",
       "      <td>Nickelback Lyrics: Real or Fake?</td>\n",
       "      <td>Good Mythical Morning</td>\n",
       "      <td>24</td>\n",
       "      <td>2017-11-13T11:00:04.000Z</td>\n",
       "      <td>rhett and link|\"gmm\"|\"good mythical morning\"|\"...</td>\n",
       "      <td>343168</td>\n",
       "      <td>10172</td>\n",
       "      <td>666</td>\n",
       "      <td>2146</td>\n",
       "      <td>https://i.ytimg.com/vi/puqaWrEC7tY/default.jpg</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Today we find out if Link is a Nickelback amat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d380meD0W0M</th>\n",
       "      <td>17.14.11</td>\n",
       "      <td>I Dare You: GOING BALD!?</td>\n",
       "      <td>nigahiga</td>\n",
       "      <td>24</td>\n",
       "      <td>2017-11-12T18:01:41.000Z</td>\n",
       "      <td>ryan|\"higa\"|\"higatv\"|\"nigahiga\"|\"i dare you\"|\"...</td>\n",
       "      <td>2095731</td>\n",
       "      <td>132235</td>\n",
       "      <td>1989</td>\n",
       "      <td>17518</td>\n",
       "      <td>https://i.ytimg.com/vi/d380meD0W0M/default.jpg</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>I know it's been a while since we did this sho...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            trending_date                                              title  \\\n",
       "video_id                                                                       \n",
       "2kyS6SvSYSE      17.14.11                 WE WANT TO TALK ABOUT OUR MARRIAGE   \n",
       "1ZAPwfrtAFY      17.14.11  The Trump Presidency: Last Week Tonight with J...   \n",
       "5qpjK5DgCt4      17.14.11  Racist Superman | Rudy Mancuso, King Bach & Le...   \n",
       "puqaWrEC7tY      17.14.11                   Nickelback Lyrics: Real or Fake?   \n",
       "d380meD0W0M      17.14.11                           I Dare You: GOING BALD!?   \n",
       "\n",
       "                     channel_title  category_id              publish_time  \\\n",
       "video_id                                                                    \n",
       "2kyS6SvSYSE           CaseyNeistat           22  2017-11-13T17:13:01.000Z   \n",
       "1ZAPwfrtAFY        LastWeekTonight           24  2017-11-13T07:30:00.000Z   \n",
       "5qpjK5DgCt4           Rudy Mancuso           23  2017-11-12T19:05:24.000Z   \n",
       "puqaWrEC7tY  Good Mythical Morning           24  2017-11-13T11:00:04.000Z   \n",
       "d380meD0W0M               nigahiga           24  2017-11-12T18:01:41.000Z   \n",
       "\n",
       "                                                          tags    views  \\\n",
       "video_id                                                                  \n",
       "2kyS6SvSYSE                                    SHANtell martin   748374   \n",
       "1ZAPwfrtAFY  last week tonight trump presidency|\"last week ...  2418783   \n",
       "5qpjK5DgCt4  racist superman|\"rudy\"|\"mancuso\"|\"king\"|\"bach\"...  3191434   \n",
       "puqaWrEC7tY  rhett and link|\"gmm\"|\"good mythical morning\"|\"...   343168   \n",
       "d380meD0W0M  ryan|\"higa\"|\"higatv\"|\"nigahiga\"|\"i dare you\"|\"...  2095731   \n",
       "\n",
       "              likes  dislikes  comment_count  \\\n",
       "video_id                                       \n",
       "2kyS6SvSYSE   57527      2966          15954   \n",
       "1ZAPwfrtAFY   97185      6146          12703   \n",
       "5qpjK5DgCt4  146033      5339           8181   \n",
       "puqaWrEC7tY   10172       666           2146   \n",
       "d380meD0W0M  132235      1989          17518   \n",
       "\n",
       "                                             thumbnail_link  \\\n",
       "video_id                                                      \n",
       "2kyS6SvSYSE  https://i.ytimg.com/vi/2kyS6SvSYSE/default.jpg   \n",
       "1ZAPwfrtAFY  https://i.ytimg.com/vi/1ZAPwfrtAFY/default.jpg   \n",
       "5qpjK5DgCt4  https://i.ytimg.com/vi/5qpjK5DgCt4/default.jpg   \n",
       "puqaWrEC7tY  https://i.ytimg.com/vi/puqaWrEC7tY/default.jpg   \n",
       "d380meD0W0M  https://i.ytimg.com/vi/d380meD0W0M/default.jpg   \n",
       "\n",
       "             comments_disabled  ratings_disabled  video_error_or_removed  \\\n",
       "video_id                                                                   \n",
       "2kyS6SvSYSE              False             False                   False   \n",
       "1ZAPwfrtAFY              False             False                   False   \n",
       "5qpjK5DgCt4              False             False                   False   \n",
       "puqaWrEC7tY              False             False                   False   \n",
       "d380meD0W0M              False             False                   False   \n",
       "\n",
       "                                                   description  \n",
       "video_id                                                        \n",
       "2kyS6SvSYSE  SHANTELL'S CHANNEL - https://www.youtube.com/s...  \n",
       "1ZAPwfrtAFY  One year after the presidential election, John...  \n",
       "5qpjK5DgCt4  WATCH MY PREVIOUS VIDEO ▶ \\n\\nSUBSCRIBE ► http...  \n",
       "puqaWrEC7tY  Today we find out if Link is a Nickelback amat...  \n",
       "d380meD0W0M  I know it's been a while since we did this sho...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['category_id'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40949, 15)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "title = df['title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stopWord = set(stopwords.words('english'))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_ngrams(s, n):\n",
    "    s= s.lower()\n",
    "    s = re.sub(r'[^a-zA-Z0-9\\s]', ' ', s)\n",
    "    s = re.sub(r'[0-9]+', ' ', s)\n",
    "    \n",
    "    s = nltk.PorterStemmer().stem(nltk.WordNetLemmatizer().lemmatize(s, pos='v'))\n",
    "\n",
    "    tokens = word_tokenize(s)\n",
    "    \n",
    "    tokens = [token for token in tokens if token not in stopWord and len(token) > 3]\n",
    "    \n",
    "    output = list(ngrams(tokens, n))\n",
    "    return(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'WE WANT TO TALK ABOUT OUR MARRIAGE'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('want',), ('talk',), ('marriag',)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_ngrams(title[0], 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# create df_title with key_word\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "related_cols = ['title', 'category_id']\n",
    "df_title = df[related_cols]\n",
    "df_title['key_word'] = '0'\n",
    "df_title = df_title.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_title.at[0, 'key_word'] = generate_ngrams(df_title.loc[0, 'title'], n=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(df_title.shape[0]):\n",
    "    df_title.at[i, 'key_word'] = generate_ngrams(df_title.loc[i, 'title'], n=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>category_id</th>\n",
       "      <th>key_word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WE WANT TO TALK ABOUT OUR MARRIAGE</td>\n",
       "      <td>22</td>\n",
       "      <td>[(want,), (talk,), (marriag,)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Trump Presidency: Last Week Tonight with J...</td>\n",
       "      <td>24</td>\n",
       "      <td>[(trump,), (presidency,), (last,), (week,), (t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Racist Superman | Rudy Mancuso, King Bach &amp; Le...</td>\n",
       "      <td>23</td>\n",
       "      <td>[(racist,), (superman,), (rudy,), (mancuso,), ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Nickelback Lyrics: Real or Fake?</td>\n",
       "      <td>24</td>\n",
       "      <td>[(nickelback,), (lyrics,), (real,), (fake,)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I Dare You: GOING BALD!?</td>\n",
       "      <td>24</td>\n",
       "      <td>[(dare,), (going,), (bald,)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2 Weeks with iPhone X</td>\n",
       "      <td>28</td>\n",
       "      <td>[(weeks,), (iphone,)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Roy Moore &amp; Jeff Sessions Cold Open - SNL</td>\n",
       "      <td>24</td>\n",
       "      <td>[(moore,), (jeff,), (sessions,), (cold,), (ope...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5 Ice Cream Gadgets put to the Test</td>\n",
       "      <td>28</td>\n",
       "      <td>[(cream,), (gadgets,), (test,)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>The Greatest Showman | Official Trailer 2 [HD]...</td>\n",
       "      <td>1</td>\n",
       "      <td>[(greatest,), (showman,), (official,), (traile...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Why the rise of the robots won’t mean the end ...</td>\n",
       "      <td>25</td>\n",
       "      <td>[(rise,), (robots,), (mean,), (work,)]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  category_id  \\\n",
       "0                 WE WANT TO TALK ABOUT OUR MARRIAGE           22   \n",
       "1  The Trump Presidency: Last Week Tonight with J...           24   \n",
       "2  Racist Superman | Rudy Mancuso, King Bach & Le...           23   \n",
       "3                   Nickelback Lyrics: Real or Fake?           24   \n",
       "4                           I Dare You: GOING BALD!?           24   \n",
       "5                              2 Weeks with iPhone X           28   \n",
       "6          Roy Moore & Jeff Sessions Cold Open - SNL           24   \n",
       "7                5 Ice Cream Gadgets put to the Test           28   \n",
       "8  The Greatest Showman | Official Trailer 2 [HD]...            1   \n",
       "9  Why the rise of the robots won’t mean the end ...           25   \n",
       "\n",
       "                                            key_word  \n",
       "0                     [(want,), (talk,), (marriag,)]  \n",
       "1  [(trump,), (presidency,), (last,), (week,), (t...  \n",
       "2  [(racist,), (superman,), (rudy,), (mancuso,), ...  \n",
       "3       [(nickelback,), (lyrics,), (real,), (fake,)]  \n",
       "4                       [(dare,), (going,), (bald,)]  \n",
       "5                              [(weeks,), (iphone,)]  \n",
       "6  [(moore,), (jeff,), (sessions,), (cold,), (ope...  \n",
       "7                    [(cream,), (gadgets,), (test,)]  \n",
       "8  [(greatest,), (showman,), (official,), (traile...  \n",
       "9             [(rise,), (robots,), (mean,), (work,)]  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_title.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6455, 3)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_title_unique = df_title.drop_duplicates(subset = 'title', keep = 'first')\n",
    "df_title_unique.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_title_unique['key_word'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('want',)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_title_unique.loc[0, 'key_word'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<6455x9251 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 32880 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v = DictVectorizer()\n",
    "X = v.fit_transform(Counter(f) for f in (df_title_unique['key_word']))\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6455"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X\n",
    "X.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9251"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "key_word_cols = v.get_feature_names()\n",
    "len(key_word_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(len(key_word_cols)):\n",
    "    s = str(key_word_cols[i])\n",
    "    s = s[2:-3]\n",
    "    key_word_cols[i] = s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LDA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda\\lib\\site-packages\\sklearn\\decomposition\\online_lda.py:536: DeprecationWarning: The default value for 'learning_method' will be changed from 'online' to 'batch' in the release 0.20. This warning was introduced in 0.18.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.015625  , 0.015625  , 0.015625  , ..., 0.015625  , 0.015625  ,\n",
       "        0.015625  ],\n",
       "       [0.1328125 , 0.0078125 , 0.0078125 , ..., 0.38281248, 0.0078125 ,\n",
       "        0.0078125 ],\n",
       "       [0.0078125 , 0.0078125 , 0.0078125 , ..., 0.0078125 , 0.0078125 ,\n",
       "        0.0078125 ],\n",
       "       ...,\n",
       "       [0.00892857, 0.00892857, 0.00892857, ..., 0.15178571, 0.00892857,\n",
       "        0.00892857],\n",
       "       [0.01041667, 0.01041667, 0.01041667, ..., 0.01041667, 0.01041667,\n",
       "        0.01041667],\n",
       "       [0.01041667, 0.17708333, 0.01041667, ..., 0.01041667, 0.17708333,\n",
       "        0.01041667]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run LDA model\n",
    "lda = LatentDirichletAllocation(n_components=16, max_iter=10, random_state=0)\n",
    "lda.fit(X)\n",
    "lda.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6455, 16)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_df = pd.DataFrame(data = lda.transform(X))\n",
    "output_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "category_id = []\n",
    "for i in range(output_df.shape[0]):\n",
    "    prob = output_df.loc[i, :].tolist()\n",
    "    prob = np.array(prob)\n",
    "    category = np.argmax(prob)\n",
    "    category_id.append(category)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>category_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.265625</td>\n",
       "      <td>0.515625</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.132813</td>\n",
       "      <td>0.007813</td>\n",
       "      <td>0.007813</td>\n",
       "      <td>0.007813</td>\n",
       "      <td>0.007813</td>\n",
       "      <td>0.007813</td>\n",
       "      <td>0.007813</td>\n",
       "      <td>0.007813</td>\n",
       "      <td>0.007813</td>\n",
       "      <td>0.132813</td>\n",
       "      <td>0.007813</td>\n",
       "      <td>0.257813</td>\n",
       "      <td>0.007813</td>\n",
       "      <td>0.382812</td>\n",
       "      <td>0.007813</td>\n",
       "      <td>0.007813</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.007813</td>\n",
       "      <td>0.007813</td>\n",
       "      <td>0.007813</td>\n",
       "      <td>0.007813</td>\n",
       "      <td>0.007813</td>\n",
       "      <td>0.882812</td>\n",
       "      <td>0.007813</td>\n",
       "      <td>0.007813</td>\n",
       "      <td>0.007813</td>\n",
       "      <td>0.007813</td>\n",
       "      <td>0.007813</td>\n",
       "      <td>0.007813</td>\n",
       "      <td>0.007813</td>\n",
       "      <td>0.007813</td>\n",
       "      <td>0.007813</td>\n",
       "      <td>0.007813</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.012500</td>\n",
       "      <td>0.012500</td>\n",
       "      <td>0.012500</td>\n",
       "      <td>0.012500</td>\n",
       "      <td>0.012500</td>\n",
       "      <td>0.012500</td>\n",
       "      <td>0.012500</td>\n",
       "      <td>0.012500</td>\n",
       "      <td>0.012500</td>\n",
       "      <td>0.012500</td>\n",
       "      <td>0.012500</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>0.012500</td>\n",
       "      <td>0.012500</td>\n",
       "      <td>0.012500</td>\n",
       "      <td>0.012500</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.765625</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0  0.015625  0.015625  0.015625  0.015625  0.015625  0.015625  0.015625   \n",
       "1  0.132813  0.007813  0.007813  0.007813  0.007813  0.007813  0.007813   \n",
       "2  0.007813  0.007813  0.007813  0.007813  0.007813  0.882812  0.007813   \n",
       "3  0.012500  0.012500  0.012500  0.012500  0.012500  0.012500  0.012500   \n",
       "4  0.015625  0.015625  0.015625  0.015625  0.765625  0.015625  0.015625   \n",
       "\n",
       "          7         8         9        10        11        12        13  \\\n",
       "0  0.015625  0.265625  0.515625  0.015625  0.015625  0.015625  0.015625   \n",
       "1  0.007813  0.007813  0.132813  0.007813  0.257813  0.007813  0.382812   \n",
       "2  0.007813  0.007813  0.007813  0.007813  0.007813  0.007813  0.007813   \n",
       "3  0.012500  0.012500  0.012500  0.012500  0.812500  0.012500  0.012500   \n",
       "4  0.015625  0.015625  0.015625  0.015625  0.015625  0.015625  0.015625   \n",
       "\n",
       "         14        15  category_id  \n",
       "0  0.015625  0.015625            9  \n",
       "1  0.007813  0.007813           13  \n",
       "2  0.007813  0.007813            5  \n",
       "3  0.012500  0.012500           11  \n",
       "4  0.015625  0.015625            4  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_df['category_id'] = category_id\n",
    "output_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output_df.to_csv('C:/Users/chenq/Desktop/output_df.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9251\n",
      "9251\n",
      "9251\n",
      "9251\n",
      "9251\n",
      "9251\n",
      "9251\n",
      "9251\n",
      "9251\n",
      "9251\n",
      "9251\n",
      "9251\n",
      "9251\n",
      "9251\n",
      "9251\n",
      "9251\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,16):\n",
    "    print(lda.components_[[i]].size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.9722842124066463e-07\n",
      "2.7135546935273326e-08\n",
      "3.318666939208937e-08\n",
      "3.664028095294841e-08\n",
      "3.4611563204293166e-08\n",
      "1.5077910518976917e-08\n",
      "3.6913824787248573e-08\n",
      "3.0717533016564197e-08\n",
      "2.095346015408369e-07\n",
      "3.856985534495164e-08\n",
      "2.8307072012470677e-08\n",
      "5.739856007233624e-08\n",
      "2.2397556053284266e-08\n",
      "4.447958789536143e-08\n",
      "3.778088183151236e-08\n",
      "2.5896827186111328e-08\n"
     ]
    }
   ],
   "source": [
    "# Check the covariance. In each cluster, in oder to check, we run over it with 100000000\n",
    "for i in range(0,16):\n",
    "    print(np.cov(lda.components_[[i]])/100000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_top_words(model, feature_names, n_top_words):\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        message = \"Topic #%d: \" % topic_idx\n",
    "        message += \", \".join([feature_names[i] for i in topic.argsort()[:-n_top_words-1:-1]])\n",
    "        print(message)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic #0: official, trailer, live, game, world, super, season, teaser, american, week, smith, highlight, awards, jimmy, film\n",
      "Topic #1: things, tour, refinery, ball, never, google, hart, secret, meet, fair, dead, getting, vanity, fashion, sport\n",
      "Topic #2: challenge, look, tried, school, cake, giant, everything, baby, kardashian, grace, slow, short, wrong, chocolate, make\n",
      "Topic #3: first, year, netflix, time, inside, hair, talks, league, justin, disney, show, says, taylor, money, timberlake\n",
      "Topic #4: trail, lyric, official, feat, honest, wild, trailers, final, room, family, sean, makeover, nintendo, much, speaks\n",
      "Topic #5: like, ready, special, idol, conan, view, king, coming, charlie, greatest, century, record, trick, dream, santa\n",
      "Topic #6: james, espn, show, people, battle, lebron, ever, michael, ellen, good, olympics, kitchen, using, stop, cast\n",
      "Topic #7: full, behind, know, commercial, infinity, avengers, high, today, marvel, performance, highlights, dance, fire, florida, award\n",
      "Topic #8: video, official, music, make, talk, perfect, made, voice, vogu, song, miss, apple, first, shawn, scott\n",
      "Topic #9: makeup, test, trump, makes, wedding, face, taste, shooting, donald, artist, wwhl, hawaii, tutori, president, blood\n",
      "Topic #10: black, movie, review, gets, panther, home, brown, scene, friend, emotional, babish, without, running, three, hour\n",
      "Topic #11: love, last, christmas, stephen, john, react, night, real, beauty, first, making, every, jedi, kevin, espn\n",
      "Topic #12: take, life, food, white, breaks, david, amazon, earth, japanese, lost, simon, tesla, dogs, launch, ariana\n",
      "Topic #13: audio, bowl, part, official, goes, cardi, chris, questions, girl, graham, holiday, show, norton, falcon, heavy\n",
      "Topic #14: star, wars, watch, house, episode, kids, back, open, adam, america, cooking, interview, press, dancing, come\n",
      "Topic #15: best, golden, youtube, camila, mendes, cabello, shows, jordan, bought, york, college, actually, shopping, solo, volcano\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_top_words(lda, key_word_cols, 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
